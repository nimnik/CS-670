{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pBGYxn1HPdwd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"Combined_News_DJIA.csv\", encoding='latin-1')\n",
        "\n",
        "s = [\"Date\", \"Label\"]\n",
        "for i in range(1, 26):\n",
        "    s += [\"Top\" + str(i)]\n",
        "\n",
        "data_list = []\n",
        "\n",
        "for i in range(27):\n",
        "    data_list.append(data[s[i]].tolist())\n",
        "\n",
        "count = 0\n",
        "try:\n",
        "    for i in range(2, 27):\n",
        "        for j in range(len(data)):\n",
        "            if type(data_list[i][j]) == float:\n",
        "                data_list[i][j] = \"None\"\n",
        "            else:\n",
        "                count += 1\n",
        "                data_list[i][j] = data_list[i][j][2:-1]\n",
        "except:\n",
        "    print(i, j,count)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = 25\n",
        "\n",
        "if (num_features > 1):\n",
        "    topn = []\n",
        "\n",
        "    for j in range(len(data)):\n",
        "      x = \"\"\n",
        "\n",
        "      for i in range(2, num_features + 1):\n",
        "        x += data_list[i][j] + \" \"\n",
        "      x += data_list[num_features + 1][j]\n",
        "      topn.append(x)\n",
        "\n",
        "else:\n",
        "     topn = data_list[2]"
      ],
      "metadata": {
        "id": "lpayx1xjwh6k"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict = {}\n",
        "label_dict = {}\n",
        "\n",
        "for i in range(1, 26):\n",
        "    data_dict[\"Top\" + str(i)] = data_list[i+1]\n",
        "\n",
        "label_dict[\"Label\"] = data_list[1]\n",
        "\n",
        "train_df = pd.DataFrame(data_dict)\n",
        "label_df = pd.DataFrame(label_dict)\n",
        "\n",
        "# train_df.head()\n",
        "# label_df.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-JHDAPwCUz9A"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top1 = [wrd.split() for wrd in topn]\n",
        "top1[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrGd8Lpim5y7",
        "outputId": "0457399d-47ab-4e65-a275-b14d1738bea1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Georgia',\n",
              " \"'downs\",\n",
              " 'two',\n",
              " 'Russian',\n",
              " \"warplanes'\",\n",
              " 'as',\n",
              " 'countries',\n",
              " 'move',\n",
              " 'to',\n",
              " 'brink',\n",
              " 'of',\n",
              " 'war',\n",
              " 'BREAKING:',\n",
              " 'Musharraf',\n",
              " 'to',\n",
              " 'be',\n",
              " 'impeached.',\n",
              " 'Russia',\n",
              " 'Today:',\n",
              " 'Columns',\n",
              " 'of',\n",
              " 'troops',\n",
              " 'roll',\n",
              " 'into',\n",
              " 'South',\n",
              " 'Ossetia;',\n",
              " 'footage',\n",
              " 'from',\n",
              " 'fighting',\n",
              " '(YouTube)',\n",
              " 'Russian',\n",
              " 'tanks',\n",
              " 'are',\n",
              " 'moving',\n",
              " 'towards',\n",
              " 'the',\n",
              " 'capital',\n",
              " 'of',\n",
              " 'South',\n",
              " 'Ossetia,',\n",
              " 'which',\n",
              " 'has',\n",
              " 'reportedly',\n",
              " 'been',\n",
              " 'completely',\n",
              " 'destroyed',\n",
              " 'by',\n",
              " 'Georgian',\n",
              " 'artillery',\n",
              " 'fire',\n",
              " 'Afghan',\n",
              " 'children',\n",
              " 'raped',\n",
              " 'with',\n",
              " \"'impunity,'\",\n",
              " 'U.N.',\n",
              " 'official',\n",
              " 'says',\n",
              " '-',\n",
              " 'this',\n",
              " 'is',\n",
              " 'sick,',\n",
              " 'a',\n",
              " 'three',\n",
              " 'year',\n",
              " 'old',\n",
              " 'was',\n",
              " 'raped',\n",
              " 'and',\n",
              " 'they',\n",
              " 'do',\n",
              " 'nothing',\n",
              " '150',\n",
              " 'Russian',\n",
              " 'tanks',\n",
              " 'have',\n",
              " 'entered',\n",
              " 'South',\n",
              " 'Ossetia',\n",
              " 'whilst',\n",
              " 'Georgia',\n",
              " 'shoots',\n",
              " 'down',\n",
              " 'two',\n",
              " 'Russian',\n",
              " 'jets.',\n",
              " 'Breaking:',\n",
              " 'Georgia',\n",
              " 'invades',\n",
              " 'South',\n",
              " 'Ossetia,',\n",
              " 'Russia',\n",
              " 'warned',\n",
              " 'it',\n",
              " 'would',\n",
              " 'intervene',\n",
              " 'on',\n",
              " \"SO's\",\n",
              " 'side',\n",
              " 'The',\n",
              " \"'enemy\",\n",
              " \"combatent'\",\n",
              " 'trials',\n",
              " 'are',\n",
              " 'nothing',\n",
              " 'but',\n",
              " 'a',\n",
              " 'sham:',\n",
              " 'Salim',\n",
              " 'Haman',\n",
              " 'has',\n",
              " 'been',\n",
              " 'sentenced',\n",
              " 'to',\n",
              " '5',\n",
              " '1/2',\n",
              " 'years,',\n",
              " 'but',\n",
              " 'will',\n",
              " 'be',\n",
              " 'kept',\n",
              " 'longer',\n",
              " 'anyway',\n",
              " 'just',\n",
              " 'because',\n",
              " 'they',\n",
              " 'feel',\n",
              " 'like',\n",
              " 'it.',\n",
              " 'Georgian',\n",
              " 'troops',\n",
              " 'retreat',\n",
              " 'from',\n",
              " 'S.',\n",
              " 'Osettain',\n",
              " 'capital,',\n",
              " 'presumably',\n",
              " 'leaving',\n",
              " 'several',\n",
              " 'hundred',\n",
              " 'people',\n",
              " 'killed.',\n",
              " '[VIDEO]',\n",
              " 'Did',\n",
              " 'the',\n",
              " 'U.S.',\n",
              " 'Prep',\n",
              " 'Georgia',\n",
              " 'for',\n",
              " 'War',\n",
              " 'with',\n",
              " 'Russia?',\n",
              " 'Rice',\n",
              " 'Gives',\n",
              " 'Green',\n",
              " 'Light',\n",
              " 'for',\n",
              " 'Israel',\n",
              " 'to',\n",
              " 'Attack',\n",
              " 'Iran:',\n",
              " 'Says',\n",
              " 'U.S.',\n",
              " 'has',\n",
              " 'no',\n",
              " 'veto',\n",
              " 'over',\n",
              " 'Israeli',\n",
              " 'military',\n",
              " 'ops',\n",
              " 'Announcing:Class',\n",
              " 'Action',\n",
              " 'Lawsuit',\n",
              " 'on',\n",
              " 'Behalf',\n",
              " 'of',\n",
              " 'American',\n",
              " 'Public',\n",
              " 'Against',\n",
              " 'the',\n",
              " 'FBI',\n",
              " 'So---Russia',\n",
              " 'and',\n",
              " 'Georgia',\n",
              " 'are',\n",
              " 'at',\n",
              " 'war',\n",
              " 'and',\n",
              " 'the',\n",
              " \"NYT's\",\n",
              " 'top',\n",
              " 'story',\n",
              " 'is',\n",
              " 'opening',\n",
              " 'ceremonies',\n",
              " 'of',\n",
              " 'the',\n",
              " 'Olympics?',\n",
              " 'What',\n",
              " 'a',\n",
              " 'fucking',\n",
              " 'disgrace',\n",
              " 'and',\n",
              " 'yet',\n",
              " 'further',\n",
              " 'proof',\n",
              " 'of',\n",
              " 'the',\n",
              " 'decline',\n",
              " 'of',\n",
              " 'journalism.',\n",
              " 'China',\n",
              " 'tells',\n",
              " 'Bush',\n",
              " 'to',\n",
              " 'stay',\n",
              " 'out',\n",
              " 'of',\n",
              " 'other',\n",
              " \"countries'\",\n",
              " 'affairs',\n",
              " 'Did',\n",
              " 'World',\n",
              " 'War',\n",
              " 'III',\n",
              " 'start',\n",
              " 'today?',\n",
              " 'Georgia',\n",
              " 'Invades',\n",
              " 'South',\n",
              " 'Ossetia',\n",
              " '-',\n",
              " 'if',\n",
              " 'Russia',\n",
              " 'gets',\n",
              " 'involved,',\n",
              " 'will',\n",
              " 'NATO',\n",
              " 'absorb',\n",
              " 'Georgia',\n",
              " 'and',\n",
              " 'unleash',\n",
              " 'a',\n",
              " 'full',\n",
              " 'scale',\n",
              " 'war?',\n",
              " 'Al-Qaeda',\n",
              " 'Faces',\n",
              " 'Islamist',\n",
              " 'Backlash',\n",
              " 'Condoleezza',\n",
              " 'Rice:',\n",
              " '\"The',\n",
              " 'US',\n",
              " 'would',\n",
              " 'not',\n",
              " 'act',\n",
              " 'to',\n",
              " 'prevent',\n",
              " 'an',\n",
              " 'Israeli',\n",
              " 'strike',\n",
              " 'on',\n",
              " 'Iran.\"',\n",
              " 'Israeli',\n",
              " 'Defense',\n",
              " 'Minister',\n",
              " 'Ehud',\n",
              " 'Barak:',\n",
              " '\"Israel',\n",
              " 'is',\n",
              " 'prepared',\n",
              " 'for',\n",
              " 'uncompromising',\n",
              " 'victory',\n",
              " 'in',\n",
              " 'the',\n",
              " 'case',\n",
              " 'of',\n",
              " 'military',\n",
              " 'hostilities.\"',\n",
              " 'This',\n",
              " 'is',\n",
              " 'a',\n",
              " 'busy',\n",
              " 'day:',\n",
              " 'The',\n",
              " 'European',\n",
              " 'Union',\n",
              " 'has',\n",
              " 'approved',\n",
              " 'new',\n",
              " 'sanctions',\n",
              " 'against',\n",
              " 'Iran',\n",
              " 'in',\n",
              " 'protest',\n",
              " 'at',\n",
              " 'its',\n",
              " 'nuclear',\n",
              " 'programme.',\n",
              " 'Georgia',\n",
              " 'will',\n",
              " 'withdraw',\n",
              " '1,000',\n",
              " 'soldiers',\n",
              " 'from',\n",
              " 'Iraq',\n",
              " 'to',\n",
              " 'help',\n",
              " 'fight',\n",
              " 'off',\n",
              " 'Russian',\n",
              " 'forces',\n",
              " 'in',\n",
              " \"Georgia's\",\n",
              " 'breakaway',\n",
              " 'region',\n",
              " 'of',\n",
              " 'South',\n",
              " 'Ossetia',\n",
              " 'Why',\n",
              " 'the',\n",
              " 'Pentagon',\n",
              " 'Thinks',\n",
              " 'Attacking',\n",
              " 'Iran',\n",
              " 'is',\n",
              " 'a',\n",
              " 'Bad',\n",
              " 'Idea',\n",
              " '-',\n",
              " 'US',\n",
              " 'News',\n",
              " '&amp;',\n",
              " 'World',\n",
              " 'Report',\n",
              " 'Caucasus',\n",
              " 'in',\n",
              " 'crisis:',\n",
              " 'Georgia',\n",
              " 'invades',\n",
              " 'South',\n",
              " 'Ossetia',\n",
              " 'Indian',\n",
              " 'shoe',\n",
              " 'manufactory',\n",
              " '-',\n",
              " 'And',\n",
              " 'again',\n",
              " 'in',\n",
              " 'a',\n",
              " 'series',\n",
              " 'of',\n",
              " '\"you',\n",
              " 'do',\n",
              " 'not',\n",
              " 'like',\n",
              " 'your',\n",
              " 'work?\"',\n",
              " 'Visitors',\n",
              " 'Suffering',\n",
              " 'from',\n",
              " 'Mental',\n",
              " 'Illnesses',\n",
              " 'Banned',\n",
              " 'from',\n",
              " 'Olympics',\n",
              " 'No',\n",
              " 'Help',\n",
              " 'for',\n",
              " \"Mexico's\",\n",
              " 'Kidnapping',\n",
              " 'Surge']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This code is coppied from the following source:\n",
        "# https://github.com/dilipvaleti/Binary-Classification-using-word2vect/blob/main/Classification%20using%20word2vect.ipynb\n",
        "\n",
        "import gensim\n",
        "import numpy as np\n",
        "\n",
        "# Train the word2vec model\n",
        "w2v_model = gensim.models.Word2Vec(top1[:1500],\n",
        "                                   vector_size=100,\n",
        "                                   window=5,\n",
        "                                   min_count=2)"
      ],
      "metadata": {
        "id": "cPNBMP6yVjwL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This code is coppied from the following source:\n",
        "# https://github.com/dilipvaleti/Binary-Classification-using-word2vect/blob/main/Classification%20using%20word2vect.ipynb\n",
        " (w2v_model.wv['flight']).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufU-l0UOmwMS",
        "outputId": "7ef0233c-1324-4b6f-f579-725c5ebc585d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This code is coppied from the following source:\n",
        "# https://github.com/dilipvaleti/Binary-Classification-using-word2vect/blob/main/Classification%20using%20word2vect.ipynb\n",
        "\n",
        "# Generate aggregated sentence vectors based on the word vectors for each word in the sentence\n",
        "# Replace the words in each text message with the learned word vector\n",
        "words = set(w2v_model.wv.index_to_key )\n",
        "\n",
        "main_list = []\n",
        "main_list_test = []\n",
        "\n",
        "for news in top1[:1500]:\n",
        "  data_vec = []\n",
        "  for word in news:\n",
        "    if word in words:\n",
        "      data_vec.append(w2v_model.wv[word])\n",
        "  main_list.append(np.array(data_vec))\n",
        "\n",
        "for news in top1[1500:]:\n",
        "  data_vec = []\n",
        "  for word in news:\n",
        "    if word in words:\n",
        "      data_vec.append(w2v_model.wv[word])\n",
        "  main_list_test.append(np.array(data_vec))\n",
        "\n",
        "X_train_vect_avg = []\n",
        "for v in main_list:\n",
        "    if v.size:\n",
        "        X_train_vect_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        X_train_vect_avg.append(np.zeros(100, dtype=float))\n",
        "\n",
        "X_test_vect_avg = []\n",
        "for v in main_list_test:\n",
        "    if v.size:\n",
        "        X_test_vect_avg.append(v.mean(axis=0))\n",
        "    else:\n",
        "        X_test_vect_avg.append(np.zeros(100, dtype=float))"
      ],
      "metadata": {
        "id": "BI4uw5qBrT2Q"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This code is coppied from the following source:\n",
        "# https://github.com/dilipvaleti/Binary-Classification-using-word2vect/blob/main/Classification%20using%20word2vect.ipynb\n",
        "\n",
        "# Instantiate and fit a basic Random Forest model on top of the vectors\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf_model = rf.fit(np.array(X_train_vect_avg), np.array(data_list[1][:1500]))"
      ],
      "metadata": {
        "id": "R79u1N3gsRR3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This code is coppied from the following source:\n",
        "# https://github.com/dilipvaleti/Binary-Classification-using-word2vect/blob/main/Classification%20using%20word2vect.ipynb\n",
        "\n",
        "# Evaluate the predictions of the model on the holdout test set\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "y_test = np.array(data_list[1][1500:])\n",
        "\n",
        "y_pred = rf_model.predict(np.array(X_test_vect_avg))\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "accuracy = (y_pred==y_test).sum()/len(y_pred)\n",
        "\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ztjafUjs7OQ",
        "outputId": "6f39db3e-582d-4f03-c71d-3595e10cb3ad"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45807770961145194"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This code is coppied from the following source:\n",
        "# https://inside-machinelearning.com/en/a-simple-and-efficient-model-for-binary-classification-in-nlp/#Create_our_Deep_Learning_model_-_Binary_Classification_NLP\n",
        "\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(100,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "nn_train = np.array(X_train_vect_avg).astype('float32')\n",
        "nn_label = np.array(data_list[1][:1500]).astype('float32')\n",
        "\n",
        "history = model.fit(nn_train,\n",
        "                    nn_label,\n",
        "                    epochs=20,\n",
        "                    batch_size=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvQi7RAOvttQ",
        "outputId": "e9e6ca29-b139-47f5-e6eb-5855793e5210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.6931 - accuracy: 0.5287\n",
            "Epoch 2/20\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.6930 - accuracy: 0.5327\n",
            "Epoch 3/20\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.6911 - accuracy: 0.5413\n",
            "Epoch 4/20\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.6900 - accuracy: 0.5413\n",
            "Epoch 5/20\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.6910 - accuracy: 0.5413\n",
            "Epoch 6/20\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6907 - accuracy: 0.5413\n",
            "Epoch 7/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.6908 - accuracy: 0.5413\n",
            "Epoch 8/20\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.6904 - accuracy: 0.5413\n",
            "Epoch 9/20\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.6906 - accuracy: 0.5413\n",
            "Epoch 10/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.6910 - accuracy: 0.5413\n",
            "Epoch 11/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.6905 - accuracy: 0.5413\n",
            "Epoch 12/20\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.6904 - accuracy: 0.5413\n",
            "Epoch 13/20\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.6902 - accuracy: 0.5413\n",
            "Epoch 14/20\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.6906 - accuracy: 0.5413\n",
            "Epoch 15/20\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.6905 - accuracy: 0.5413\n",
            "Epoch 16/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.6908 - accuracy: 0.5413\n",
            "Epoch 17/20\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.6905 - accuracy: 0.5413\n",
            "Epoch 18/20\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.6904 - accuracy: 0.5413\n",
            "Epoch 19/20\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.6906 - accuracy: 0.5413\n",
            "Epoch 20/20\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.6900 - accuracy: 0.5413\n"
          ]
        }
      ]
    }
  ]
}